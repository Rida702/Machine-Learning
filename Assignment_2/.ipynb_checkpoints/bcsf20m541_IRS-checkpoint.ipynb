{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e50ccf1",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0293b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1eee1e",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "819f9019",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Here we have intialized some variables, you can add more if required.\n",
    "file_count = 0 # file_count to count number of files\n",
    "files_dict = {} # files_dic to store count of every file \n",
    "unique_word_set = set() # unique_word_set to store all the unique words i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dbd53ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number of files\n",
      " 3\n",
      "\n",
      "Dictionary containing files\n",
      " {'f1.txt': ['This', 'is', 'my', 'book'], 'f2.txt': ['This', 'is', 'my', 'pen'], 'f3.txt': ['My', 'book', 'is', 'intresting']}\n"
     ]
    }
   ],
   "source": [
    "directory = 'files'\n",
    "files = os.listdir(directory)\n",
    "count = 0\n",
    "\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(directory, file)):\n",
    "        file_count += 1 \n",
    "    with open(os.path.join(directory, file), 'r') as file_obj:\n",
    "        file_contents = file_obj.read()\n",
    "        words = file_contents.split()\n",
    "        \n",
    "        files_dict[file] = words\n",
    "print(\"\\nTotal Number of files\\n\", file_count)\n",
    "print(\"\\nDictionary containing files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c44af",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "566f8335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'my', 'book', 'this', 'is', 'my', 'pen', 'my', 'book', 'is', 'intresting']\n",
      "\n",
      "Total Number of files\n",
      " 3\n",
      "Unique words in File\n",
      " {'is', 'my', 'this', 'book', 'pen', 'intresting'}\n",
      "Dictionary of unique words {'is': 1, 'my': 2, 'this': 3, 'book': 4, 'pen': 5, 'intresting': 6}\n"
     ]
    }
   ],
   "source": [
    "directory = 'files'\n",
    "files = os.listdir(directory)\n",
    "file_count=0\n",
    "data_list = []\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(directory, file)):\n",
    "        file_count += 1 \n",
    "    with open(os.path.join(directory, file), 'r') as file_obj:\n",
    "        file_contents = file_obj.read()\n",
    "        words = file_contents.split()\n",
    "        for word in words:\n",
    "            word = word.strip().lower()\n",
    "            data_list.append(word)\n",
    "\n",
    "# Access the list\n",
    "print(data_list)\n",
    "unique_word_set = set(data_list)\n",
    "print(\"\\nTotal Number of files\\n\", file_count)\n",
    "print('Unique words in File\\n', unique_word_set)\n",
    "\n",
    "\n",
    "# Create a dictionary with list items as keys and unique digits as values\n",
    "unique_word_set = {item: i+1 for i, item in enumerate(unique_word_set)}\n",
    "\n",
    "# Print the dictionary\n",
    "\n",
    "print('Dictionary of unique words', unique_word_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d73f0",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3c6664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERM DOC MATRIX Initially:\n",
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "Dictionary of Unique Words {'is': 1, 'my': 2, 'this': 3, 'book': 4, 'pen': 5, 'intresting': 6}\n",
      "Dictionary of Files {'f1.txt': ['This', 'is', 'my', 'book'], 'f2.txt': ['This', 'is', 'my', 'pen'], 'f3.txt': ['My', 'book', 'is', 'intresting']}\n"
     ]
    }
   ],
   "source": [
    "term_doc_matrix = np.zeros((len(files_dict), len(unique_word_set)))\n",
    "\n",
    "print(\"TERM DOC MATRIX Initially:\")\n",
    "print(term_doc_matrix)\n",
    "\n",
    "print('Dictionary of Unique Words', unique_word_set)\n",
    "print('Dictionary of Files', files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a7c98",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a1316e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'my', 'book']\n",
      "['This', 'is', 'my', 'pen']\n",
      "['My', 'book', 'is', 'intresting']\n",
      "\n",
      "Dictionary of Unique Words {'is': 1, 'my': 2, 'this': 3, 'book': 4, 'pen': 5, 'intresting': 6}\n",
      "TERM DOC MATRIX after Filling:\n",
      "[[1. 1. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 0. 1. 0.]\n",
      " [1. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "directory = 'files'\n",
    "files = os.listdir(directory)\n",
    "file_count=0\n",
    "for file in files:\n",
    "    if os.path.isfile(os.path.join(directory, file)):\n",
    "        file_count += 1 \n",
    "    with open(os.path.join(directory, file), 'r') as file_obj:\n",
    "        file_contents = file_obj.read()\n",
    "    words = file_contents.split() \n",
    "    print(words)\n",
    "    for word in words:\n",
    "        word = word.strip().lower()\n",
    "        if word in unique_word_set:\n",
    "            word_index = unique_word_set[word]\n",
    "            term_doc_matrix[file_count-1][word_index-1] = 1 \n",
    "\n",
    "print('\\nDictionary of Unique Words', unique_word_set)\n",
    "print(\"TERM DOC MATRIX after Filling:\")\n",
    "print(term_doc_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa3e8c",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a52397c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary of Unique Words {'is': 1, 'my': 2, 'this': 3, 'book': 4, 'pen': 5, 'intresting': 6}\n",
      "\n",
      "Column Vector Initially: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Write something for searching:  is my this\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1000/3673057148.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0munique_word_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mcol_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_word_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "print('\\nDictionary of Unique Words', unique_word_set)\n",
    "col_vector = np.zeros( (len(unique_word_set) , 1 ) )\n",
    "print('\\nColumn Vector Initially: \\n', col_vector)\n",
    "query = input(\"\\nWrite something for searching:  \")\n",
    "for word in query.split():\n",
    "    if word in unique_word_set:\n",
    "         word_index = unique_word_set[word]\n",
    "        col_vector[word_index-1] += 1\n",
    "print(col_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8dacb4",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "093fdff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Maximum of resultant is  0\n",
      "Index for maximum in resultant is  0\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "j = 0\n",
    "index = 0\n",
    "for i in col_vector:\n",
    "    j+=1\n",
    "    if i>max:\n",
    "        max = i\n",
    "        index = j\n",
    "\n",
    "print(col_vector)\n",
    "print(\"Maximum of resultant is \", max)\n",
    "print(\"Index for maximum in resultant is \", index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2154148",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9afa32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
